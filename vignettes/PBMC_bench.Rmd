---
title: 'Benchmarking Signac across seven sequencing technologies'
author: 'Mathew Chamberlain'
date: 'Compiled: `r format(Sys.Date(), "%B %d, %Y")`'
output:
  BiocStyle::html_document:
    fig_crop: no
    toc: true
    df_print: kable
    includes:
      after_body: footer.html
---

This vignette shows how we benchmarked Signac to annotate PBMCs sequenced with seven different technologies. We accessed the raw data from a previous [study](https://www.nature.com/articles/s41587-020-0465-8) together with previously-established cell type labels [here](https://doi.org/10.5281/zenodo.3357167).

## Processing script

All data sets were processed with the same code, replacing "data.dir" to be one of the seven folders (accessed  [here](https://doi.org/10.5281/zenodo.3357167), called "PbmcBench"). The code for running Signac and saving the results is here:

```{r read CELSeq2, message = F, eval = F}
library(Signac)
data.dir = "./Seq-Well"
fls = list.files(data.dir, full.names = T)
DataPath = fls[grepl('_pbmc1.csv', fls)]
Data <- read.csv(DataPath,row.names = 1)
LabelsPath = fls[grepl('1Labels.csv', fls)]
Labels <- as.matrix(read.csv(LabelsPath))
CV_RDataPath = fls[grepl('folds.RData', fls)]
load(CV_RDataPath)
Labels <- as.vector(Labels[,col_Index])
Data = Matrix::Matrix(t(as.matrix(Data)), sparse = T)
library(Seurat)
pbmc = CreateSeuratObject(Data)
pbmc <- NormalizeData(object = pbmc, verbose = F)
pbmc <- FindVariableFeatures(pbmc, nfeatures = 2000)
pbmc <- ScaleData(pbmc)
pbmc <- RunPCA(pbmc)
pbmc <- RunUMAP(pbmc, dims = 1:10)
pbmc <- FindNeighbors(pbmc, dims = 1:30, verbose = FALSE)
data('training_HPCA')
start_time <- Sys.time()
labels_signac = Signac(E = pbmc, R = training_HPCA, num.cores = 15)
celltypes = Generate_lbls(labels_signac, E = pbmc)
end_time <- Sys.time()
Total_Time_Signac <- as.numeric(difftime(end_time,start_time,units = 'secs'))
True_Labels_Signac <- Labels
Pred_Labels_Signac <- celltypes$CellStates
write.csv(True_Labels_Signac,paste0(data.dir,'/Signac_true.csv'),row.names = FALSE)
write.csv(Pred_Labels_Signac,paste0(data.dir,'/Signac_pred.csv'),row.names = FALSE)
write.csv(Total_Time_Signac,paste0(data.dir,'/Signac_total_time.csv'),row.names = FALSE)
```

## Benchmarking

Next, we explored to what extent Signac reproduced the "true labels" for data from different technologies. We computed statistics by pulling the "evaluate.R" code from [the original benchmarking study](https://genomebiology.biomedcentral.com/articles/10.1186/s13059-019-1795-z), available [here](https://github.com/tabdelaal/scRNAseq_Benchmark).

Note:
*[In the benchmarking study](https://genomebiology.biomedcentral.com/articles/10.1186/s13059-019-1795-z), no prior knowledge classifier performed well across all technologies (Figure 3).
*Classifiers that were trained with single cell data performed well, but exhibited technology-specific bias (Figure 3).
*"Good performance" was defined as classifiers that had an average median F1-score > 0.75.

```{r filter celseq, message = F, eval = T}
evaluate <- function(TrueLabelsPath, PredLabelsPath){
  "
  Script to evaluate the performance of the classifier.
  It returns multiple evaluation measures: the confusion matrix, median F1-score, F1-score for each class, accuracy, percentage of unlabeled, population size. 
  
  The percentage of unlabeled cells is find by checking for cells that are labeled 'Unassigned', 'unassigned', 'Unknown', 'unknown', 'Nodexx', 'rand', or 'ambiguous'.
  
  Parameters
  ----------
  TrueLabelsPath: csv file with the true labels (format: one column, no index)
  PredLabelsPath: csv file with the predicted labels (format: one column, no index)

  Returns
  -------
  Conf: confusion matrix
  MedF1 : median F1-score
  F1 : F1-score per class
  Acc : accuracy
  PercUnl : percentage of unlabeled cells
  PopSize : number of cells per cell type
  "
  
  true_lab <- unlist(read.csv(TrueLabelsPath))
  pred_lab <- unlist(read.csv(PredLabelsPath))
  pred_lab = as.character(pred_lab)
  true_lab = as.character(true_lab)
  pred_lab[pred_lab %in% c("B.memory", "B.naive", "Plasma.cells")] = "B cell"
  pred_lab[pred_lab %in% c("Mon.Classical")] = "CD14+ monocyte"
  pred_lab[pred_lab %in% c("Mon.NonClassical")] = "CD16+ monocyte"
  pred_lab[pred_lab %in% c("T.CD4.memory", "T.CD4.naive", "T.CD8.cm", "T.CD8.naive", "T.regs")] = "CD4+ T cell"
  pred_lab[pred_lab %in% c("T.CD8.em")] = "Cytotoxic T cell"
  pred_lab[pred_lab %in% c("NK")] = "Natural killer cell"
  pred_lab[pred_lab %in% c("Unclassified")] = "Unknown"
  pred_lab[pred_lab %in% c("DC")] = "Dendritic cell"
  
  unique_true <- unique(true_lab)
  unique_pred <- unique(pred_lab)
  
  unique_all <- unique(c(unique_true,unique_pred))
  conf <- table(true_lab,pred_lab)
  pop_size <- rowSums(conf)
  
  pred_lab = gsub('Node..','Node',pred_lab)
  
  conf_F1 <- table(true_lab,pred_lab,exclude = c('unassigned','Unassigned','Unknown','rand','Node','ambiguous','unknown'))
  
  F1 <- vector()
  sum_acc <- 0
  
  for (i in c(1:length(unique_true))){
    findLabel = colnames(conf_F1) == row.names(conf_F1)[i]
    if(sum(findLabel)){
      prec <- conf_F1[i,findLabel] / colSums(conf_F1)[findLabel]
      rec <- conf_F1[i,findLabel] / rowSums(conf_F1)[i]
      if (prec == 0 || rec == 0){
        F1[i] = 0
      } else{
        F1[i] <- (2*prec*rec) / (prec + rec)
      }
      sum_acc <- sum_acc + conf_F1[i,findLabel]
    } else {
      F1[i] = 0
    }
  }
  
  pop_size <- pop_size[pop_size > 0]
  
  names(F1) <- names(pop_size)
  
  med_F1 <- median(F1)
  
  total <- length(pred_lab)
  num_unlab <- sum(pred_lab == 'unassigned') + sum(pred_lab == 'Unassigned') + sum(pred_lab == 'rand') + sum(pred_lab == 'Unknown') + sum(pred_lab == 'unknown') + sum(pred_lab == 'Node') + sum(pred_lab == 'ambiguous')
  per_unlab <- num_unlab / total
  
  acc <- sum_acc/sum(conf_F1)
  
  result <- list(Conf = conf, MedF1 = med_F1, F1 = F1, Acc = acc, PercUnl = per_unlab, PopSize = pop_size)
  
  return(result)
}

fls = list.files("./PbmcBench", full.names = T)

PredLabelsPath = paste0(fls, "/Signac_pred.csv")
TrueLabelsPath = paste0(fls, "/Signac_true.csv")

PredLabelsPath = PredLabelsPath[sapply(PredLabelsPath, function(x) file.exists(x))]
TrueLabelsPath = TrueLabelsPath[sapply(TrueLabelsPath, function(x) file.exists(x))]

q = mapply(function(x,y) {evaluate(TrueLabelsPath = x, PredLabelsPath = y)}, x = TrueLabelsPath, y = PredLabelsPath, SIMPLIFY = F)

df = data.frame(CELseq = round(q$`./PbmcBench/CEL-Seq/Signac_true.csv`$MedF1, digits = 2),
                Dropseq = round(q$`./PbmcBench/Drop-Seq/Signac_true.csv`$MedF1, digits = 2),
                inDrop = round(q$`./PbmcBench/inDrop/Signac_true.csv`$MedF1, digits = 2),
                sc10Xv2 = round(q$`./PbmcBench/sc10Xv2/Signac_true.csv`$MedF1, digits = 2),
                sc10Xv3 = round(q$`./PbmcBench/sc10Xv3/Signac_true.csv`$MedF1, digits = 2),
                SeqWell = round(q$`./PbmcBench/Seq-Well/Signac_true.csv`$MedF1, digits = 2),
                SmartSeq2 = round(q$`./PbmcBench/Smart-Seq2/Signac_true.csv`$MedF1, digits = 2))
```

## Results

Median F1 scores for Signac classification in each data set:

```{r res, message = F, echo = F}
df
```

Signac average median F1 score:

```{r res2, message = F, echo = F}
mean(as.numeric(df))
```

```{r save.times, include = FALSE}
write.csv(x = t(as.data.frame(all_times)), file = "Crabeating_vignette_tutorial_times.csv")
```

## Session information

<details>
  <summary>**Session Info**</summary>
```{r, echo=FALSE}
sessionInfo()
```
</details>